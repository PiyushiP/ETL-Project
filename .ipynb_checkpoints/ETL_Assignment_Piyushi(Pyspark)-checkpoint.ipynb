{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ETL Assignment (Pyspark)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks performed in this sheet\n",
    "\n",
    "* After the data is imported in HDFS we need to read the file and create Target dimension model in Pyspark\n",
    "* Environment variable set up and Initiating SparkSession and creating sparkContext\n",
    "* Custom Schema needs to be created to avoid any data type issues\n",
    "* 4 Dimension and 1 Fact table needs to be created\n",
    "* Cleaning and Tranforming of data is done and de-duplication needs to be taken care\n",
    "* Creating Primary Key for each dimension table\n",
    "* Rearranging the fields if necessary\n",
    "* Making all Primary key available for Fact table creation\n",
    "* Write the DataFrames containing fact and dimensions directly to an s3 bucket folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Environment set up to access our code in Jupytor notebook.Here we set the path for JAVA_HOME, SPARK_HOME as well as Python library\n",
    "#### Import SparkSession : Spark session is a unified entry point of a spark application from Spark 2.0. It provides a way to interact with various spark's functionality with a lesser number of constructs.\n",
    "#### Create sparkContext entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/opt/cloudera/parcels/Anaconda/bin/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_232-cloudera/jre\"\n",
    "os.environ[\"SPARK_HOME\"]=\"/opt/cloudera/parcels/SPARK2-2.3.0.cloudera2-1.cdh5.13.3.p0.316101/lib/spark2/\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-138.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f84b49646d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('demo').master(\"local\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-138.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=demo>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Reading the data from the files in HDFS by a specific schema using PySpark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####    Creating an input schema using StructType to avoid any data type mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining Struct Types for each column based on Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileSchema = StructType([StructField('year', IntegerType(),False),\n",
    "                        StructField('month', StringType(),False),\n",
    "                        StructField('day', IntegerType(),False),\n",
    "                        StructField('weekday', StringType(),False),\n",
    "                        StructField('hour', IntegerType(),False),\n",
    "                        StructField('atm_status', StringType(),False),\n",
    "                        StructField('atm_id', StringType(),False),\n",
    "                        StructField('atm_manufacturer', StringType(),False),\n",
    "                        StructField('atm_location', StringType(),False),\n",
    "                        StructField('atm_streetname', StringType(),False),\n",
    "                        StructField('atm_street_number', IntegerType(),False),\n",
    "                        StructField('atm_zipcode', IntegerType(),False),\n",
    "                        StructField('atm_lat', DoubleType(),False),\n",
    "                        StructField('atm_lon', DoubleType(),False),\n",
    "                        StructField('currency', StringType(),False),\n",
    "                        StructField('card_type', StringType(),False),\n",
    "                        StructField('transaction_amount', IntegerType(),False), \n",
    "                        StructField('service', StringType(),False),\n",
    "                        StructField('message_code', StringType(),True),\n",
    "                        StructField('message_text', StringType(),True),\n",
    "                        StructField('weather_lat', DoubleType(),False),\n",
    "                        StructField('weather_lon', DoubleType(),False),\n",
    "                        StructField('weather_city_id', IntegerType(),False),\n",
    "                        StructField('weather_city_name', StringType(),False), \n",
    "                        StructField('temp', DoubleType(),False),\n",
    "                        StructField('pressure', IntegerType(),False), \n",
    "                        StructField('humidity', IntegerType(),False), \n",
    "                        StructField('wind_speed', IntegerType(),False), \n",
    "                        StructField('wind_deg', IntegerType(),False), \n",
    "                        StructField('rain_3h', DoubleType(),True), \n",
    "                        StructField('clouds_all', IntegerType(),False), \n",
    "                        StructField('weather_id', IntegerType(),False), \n",
    "                        StructField('weather_main', StringType(),False), \n",
    "                        StructField('weather_description', StringType(),False), \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dataframe to read the csv file with schema as the custom schema created above i.e fileSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"hdfs:/user/root/etl_assignment\", header = False, schema = fileSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking the number of records loaded from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()    # count is 2468572 which is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()   #### printSchema() method provides an easily readable view of the DataFrame schema created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekday',\n",
       " 'hour',\n",
       " 'atm_status',\n",
       " 'atm_id',\n",
       " 'atm_manufacturer',\n",
       " 'atm_location',\n",
       " 'atm_streetname',\n",
       " 'atm_street_number',\n",
       " 'atm_zipcode',\n",
       " 'atm_lat',\n",
       " 'atm_lon',\n",
       " 'currency',\n",
       " 'card_type',\n",
       " 'transaction_amount',\n",
       " 'service',\n",
       " 'message_code',\n",
       " 'message_text',\n",
       " 'weather_lat',\n",
       " 'weather_lon',\n",
       " 'weather_city_id',\n",
       " 'weather_city_name',\n",
       " 'temp',\n",
       " 'pressure',\n",
       " 'humidity',\n",
       " 'wind_speed',\n",
       " 'wind_deg',\n",
       " 'rain_3h',\n",
       " 'clouds_all',\n",
       " 'weather_id',\n",
       " 'weather_main',\n",
       " 'weather_description']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check the columns in data frame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all sql functions\n",
    "## monotonically_increasing_id() function generates monotonically increasing 64-bit integers which are unique but not necessary consecutive so combining \n",
    "## monotonically_increasing_id() with row_number() will generate the consecutive number\n",
    "## Import libraries for working with window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just above we checked schema after assigning struct types, checked number of rows loaded and column names. \n",
    "#Since all of them look expected, lets create DIMensions as per requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of dimension tables using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Command to create a data frame for the dimension according to the target schema(dimension model) provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOCATION Dim\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Column Name</th>\n",
    "      <th>Data Type</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>atm_location</td>\n",
    "      <td>VARCHAR(50)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>atm_streetname</td>\n",
    "      <td>VARCHAR(255)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_streetnumber</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_zipcode</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_lat</td>\n",
    "      <td>DECIMAL(10,3)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_lon</td>\n",
    "       <td>DECIMAL(10,3)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>PRIMARY KEY</td>\n",
    "      <td>location_id</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying LOCATION DIM From Source File.\n",
    "temp_dim_loc= df.select('atm_location','atm_streetname','atm_street_number', 'atm_zipcode', 'atm_lat', 'atm_lon')\n",
    "#Drop-Duplicates(De-Duplicating) based on Location parameters\n",
    "DIM_LOCS = temp_dim_loc.dropDuplicates((['atm_location','atm_streetname','atm_street_number', 'atm_zipcode', 'atm_lat', 'atm_lon']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----------------+-----------+-------+-------+\n",
      "|      atm_location|      atm_streetname|atm_street_number|atm_zipcode|atm_lat|atm_lon|\n",
      "+------------------+--------------------+-----------------+-----------+-------+-------+\n",
      "|        NÃƒÂ¦stved|         Farimagsvej|                8|       4700| 55.233| 11.763|\n",
      "|          Vejgaard|          Hadsundvej|               20|       9000| 57.043|   9.95|\n",
      "|          Vejgaard|          Hadsundvej|               20|       9000| 57.043|   9.95|\n",
      "|             Ikast| RÃƒÂ¥dhusstrÃƒÂ¦det|               12|       7430| 56.139|  9.154|\n",
      "|        Svogerslev|        BrÃƒÂ¸nsager|                1|       4000| 55.634| 12.018|\n",
      "|              Nibe|              Torvet|                1|       9240| 56.983|  9.639|\n",
      "|        Fredericia|    SjÃƒÂ¦llandsgade|               33|       7000| 55.564|  9.757|\n",
      "|         Hjallerup|   Hjallerup Centret|               18|       9320| 57.168| 10.148|\n",
      "|       GlyngÃƒÂ¸re|         FÃƒÂ¦rgevej|                1|       7870| 56.762|  8.867|\n",
      "|           Hadsund|           Storegade|               12|       9560| 56.716| 10.114|\n",
      "|    NÃƒÂ¸rresundby|              Torvet|                6|       9400| 57.059|  9.922|\n",
      "|         Sauersvej|Fridtjof Nansens Vej|                2|       9210| 57.023|   9.94|\n",
      "|          Vejgaard|          Hadsundvej|               20|       9000| 57.043|   9.95|\n",
      "|ÃƒËœsterÃƒÂ¥  Duus|        ÃƒËœsterÃƒÂ¥|               12|       9000| 57.049|  9.922|\n",
      "|           SÃƒÂ¦by|          Vestergade|                3|       9300| 57.334| 10.515|\n",
      "|        HÃƒÂ¸rning|        NÃƒÂ¸rrealle|               12|       8362| 56.086| 10.037|\n",
      "|            Vestre|           Kastetvej|               36|       9000| 57.053|  9.905|\n",
      "|ÃƒËœsterÃƒÂ¥  Duus|        ÃƒËœsterÃƒÂ¥|               12|       9000| 57.049|  9.922|\n",
      "|             Skive|            Adelgade|                8|       7800| 56.567|  9.027|\n",
      "|           Randers|        ÃƒËœstervold|               16|       8900| 56.462| 10.038|\n",
      "+------------------+--------------------+-----------------+-----------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_dim_loc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_LOCS.count()   # count is 109 which is as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_id is Primary key for LOCATION Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LOC = DIM_LOCS.withColumn(\n",
    "    \"location_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[atm_location: string, atm_streetname: string, atm_street_number: int, atm_zipcode: int, atm_lat: double, atm_lon: double, location_id: int]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Order LOC DIM: Location by Primary Index\n",
    "DIM_LOC.orderBy('location_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+-----------+-------+-------+-----------+\n",
      "|     atm_location|  atm_streetname|atm_street_number|atm_zipcode|atm_lat|atm_lon|location_id|\n",
      "+-----------------+----------------+-----------------+-----------+-------+-------+-----------+\n",
      "|            Vadum|  Ellehammersvej|               43|       9430| 57.118|  9.861|          1|\n",
      "|         Slagelse| Mariendals Alle|               29|       4200| 55.398| 11.342|          2|\n",
      "|       Fredericia|SjÃƒÂ¦llandsgade|               33|       7000| 55.564|  9.757|          3|\n",
      "|          Kolding|        Vejlevej|              135|       6000| 55.505|  9.457|          4|\n",
      "|HÃƒÂ¸rning Hallen|        Toftevej|               53|       8362| 56.091| 10.033|          5|\n",
      "+-----------------+----------------+-----------------+-----------+-------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_LOC.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LOC= DIM_LOC.select('location_id','atm_location','atm_streetname','atm_street_number','atm_zipcode','atm_lat',\n",
    "                       'atm_lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------------+-----------------+-----------+-------+-------+\n",
      "|location_id|     atm_location|  atm_streetname|atm_street_number|atm_zipcode|atm_lat|atm_lon|\n",
      "+-----------+-----------------+----------------+-----------------+-----------+-------+-------+\n",
      "|          1|            Vadum|  Ellehammersvej|               43|       9430| 57.118|  9.861|\n",
      "|          2|         Slagelse| Mariendals Alle|               29|       4200| 55.398| 11.342|\n",
      "|          3|       Fredericia|SjÃƒÂ¦llandsgade|               33|       7000| 55.564|  9.757|\n",
      "|          4|          Kolding|        Vejlevej|              135|       6000| 55.505|  9.457|\n",
      "|          5|HÃƒÂ¸rning Hallen|        Toftevej|               53|       8362| 56.091| 10.033|\n",
      "+-----------+-----------------+----------------+-----------------+-----------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_LOC.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATM Dim\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Column Name</th>\n",
    "      <th>Data Type</th>\n",
    "      <th>Comments/Foreign Key</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>atm_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>atm_number</td>\n",
    "      <td>VARCHAR(20)</td>\n",
    "    </tr>\n",
    "   <tr>\n",
    "      <td>atm_manufacturer</td>\n",
    "      <td>VARCHAR(50)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_location_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_lat</td>\n",
    "      <td>DECIMAL(10,3)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>atm_lon</td>\n",
    "       <td>DECIMAL(10,3)</td>\n",
    "    </tr>\n",
    "\n",
    "<tr>\n",
    "      <td>PRIMARY KEY</td>\n",
    "      <td>atm_id</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>FOREIGN KEY</td>\n",
    "      <td>atm_location_id</td>\n",
    "      <td>REFERENCES DIM_LOCATION (location_id)</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying ATM DIM From Source File.\n",
    "#file_indexes = files.withColumnRenamed('atm_id','atm_number')\n",
    "temp_dim_atm= df.select('atm_lat','atm_lon','atm_id','atm_manufacturer')\n",
    "#Drop-Duplicates based on ATM parameters\n",
    "DIM_ATM = temp_dim_atm.dropDuplicates((['atm_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a temp table to join with location table to copy the atm location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dim_atm.registerTempTable(\"atm\")\n",
    "DIM_LOC.registerTempTable(\"loc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_ATM_TEMP= spark.sql(\"select atm.atm_id,atm.atm_manufacturer,loc.*from atm left join loc on atm.atm_lat==loc.atm_lat and atm.atm_lon==loc.atm_lon\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_ATM_TEMP.count()   # count is 156 which is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating Primary key for DIM_ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_ATM_PK = DIM_ATM_TEMP.withColumn(\"atm_prim_id\",row_number().over(Window.orderBy(monotonically_increasing_id())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[atm_id: string, atm_manufacturer: string, location_id: int, atm_location: string, atm_streetname: string, atm_street_number: int, atm_zipcode: int, atm_lat: double, atm_lon: double, atm_prim_id: int]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Order DIM: ATM by Primary Index\n",
    "DIM_ATM_PK.orderBy('atm_prim_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_ATM_PK.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_ATM = DIM_ATM_PK.select('atm_prim_id','atm.atm_id','atm_manufacturer','location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_ATM.count()   ###156 which is as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------------+-----------+\n",
      "|atm_prim_id|atm_id|atm_manufacturer|location_id|\n",
      "+-----------+------+----------------+-----------+\n",
      "|          1|    35|             NCR|         15|\n",
      "|          2|    51|             NCR|         65|\n",
      "|          3|     9| Diebold Nixdorf|         76|\n",
      "|          4|    62| Diebold Nixdorf|         30|\n",
      "|          5|    34|             NCR|         43|\n",
      "|          6|    76|             NCR|         41|\n",
      "|          7|    49|             NCR|         80|\n",
      "|          8|    88|             NCR|         66|\n",
      "|          9|    59| Diebold Nixdorf|         90|\n",
      "|         10|    93|             NCR|         55|\n",
      "|         11|    42|             NCR|         31|\n",
      "|         12|     8|             NCR|         21|\n",
      "|         13|    30|             NCR|         90|\n",
      "|         14|    89|             NCR|         88|\n",
      "|         15|   113| Diebold Nixdorf|         49|\n",
      "|         16|    79|             NCR|         29|\n",
      "|         17|   104|             NCR|         68|\n",
      "|         18|    78| Diebold Nixdorf|         64|\n",
      "|         19|    32|             NCR|        108|\n",
      "|         20|    87|             NCR|         93|\n",
      "+-----------+------+----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_ATM.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  DATE Dim\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Column Name</th>\n",
    "      <th>Data Type</th>\n",
    "       </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>date_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>full_date_time</td>\n",
    "      <td>TIMESTAMP</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>year</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>month</td>\n",
    "      <td>VARCHAR(20)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>day</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>hour</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>weekday</td>\n",
    "       <td>VARCHAR(20)</td>\n",
    "    </tr>\n",
    "\n",
    "<tr>\n",
    "      <td>PRIMARY KEY</td>\n",
    "      <td>date_id</td>\n",
    "    </tr>\n",
    "\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying DATE DIM From Source File.\n",
    "temp_dim_date= df.select('year','month','day','hour','weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Convertint String Month to Numeric\n",
    "###pyspark.sql.functions.from_unixtime(timestamp, format='yyyy-MM-dd HH:mm:ss')\n",
    "date_conv = temp_dim_date.withColumn(\"month\",from_unixtime(unix_timestamp(col(\"Month\"),'MMM'),'MM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-------+\n",
      "|year|month|day|hour|weekday|\n",
      "+----+-----+---+----+-------+\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "|2017|   01|  1|   0| Sunday|\n",
      "+----+-----+---+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_conv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column \"full_date_time\" by concatenating columns and adding delimeter using lit('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "date_conv = date_conv.withColumn('full_date_time',sf.concat(sf.col('year'),sf.lit('/'),sf.col('month'),sf.lit('/'),sf.col('day'),sf.lit(' '),sf.col('hour'),sf.lit(':'),sf.lit('00:00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-------+-----------------+\n",
      "|year|month|day|hour|weekday|   full_date_time|\n",
      "+----+-----+---+----+-------+-----------------+\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017/01/1 0:00:00|\n",
      "+----+-----+---+----+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_conv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#casting to timestamp\n",
    "date_conv2 = date_conv.withColumn('full_date_time', unix_timestamp(date_conv['full_date_time'], 'yyyy/MM/dd HH:mm:ss').cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+-------+-------------------+\n",
      "|year|month|day|hour|weekday|     full_date_time|\n",
      "+----+-----+---+----+-------+-------------------+\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "|2017|   01|  1|   0| Sunday|2017-01-01 00:00:00|\n",
      "+----+-----+---+----+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_conv2.show()   # in timestamp format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- full_date_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_conv2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De-Duplicating Data based on DATE parameters\n",
    "DIM_DATE = date_conv2.dropDuplicates((['full_date_time']))\n",
    "#Order DIM: ATM by Primary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_DATE.count()\n",
    "#Count looks as expected i.e 8685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------------------+\n",
      "|year|month|day|hour|  weekday|     full_date_time|\n",
      "+----+-----+---+----+---------+-------------------+\n",
      "|2017|   01|  5|   1| Thursday|2017-01-05 01:00:00|\n",
      "|2017|   01| 11|   8|Wednesday|2017-01-11 08:00:00|\n",
      "|2017|   01| 21|  22| Saturday|2017-01-21 22:00:00|\n",
      "|2017|   02|  7|  11|  Tuesday|2017-02-07 11:00:00|\n",
      "|2017|   02|  9|   7| Thursday|2017-02-09 07:00:00|\n",
      "|2017|   02|  9|  22| Thursday|2017-02-09 22:00:00|\n",
      "|2017|   02| 16|   5| Thursday|2017-02-16 05:00:00|\n",
      "|2017|   02| 23|  18| Thursday|2017-02-23 18:00:00|\n",
      "|2017|   02| 25|  11| Saturday|2017-02-25 11:00:00|\n",
      "|2017|   02| 26|  13|   Sunday|2017-02-26 13:00:00|\n",
      "|2017|   03| 12|  13|   Sunday|2017-03-12 13:00:00|\n",
      "|2017|   04|  1|   8| Saturday|2017-04-01 08:00:00|\n",
      "|2017|   04|  6|  14| Thursday|2017-04-06 14:00:00|\n",
      "|2017|   04| 21|  17|   Friday|2017-04-21 17:00:00|\n",
      "|2017|   05|  6|  15| Saturday|2017-05-06 15:00:00|\n",
      "|2017|   05|  9|  14|  Tuesday|2017-05-09 14:00:00|\n",
      "|2017|   05| 12|  17|   Friday|2017-05-12 17:00:00|\n",
      "|2017|   06| 13|  10|  Tuesday|2017-06-13 10:00:00|\n",
      "|2017|   06| 15|   6| Thursday|2017-06-15 06:00:00|\n",
      "|2017|   06| 20|  22|  Tuesday|2017-06-20 22:00:00|\n",
      "+----+-----+---+----+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_DATE.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding primary key\n",
    "DIM_DATE = DIM_DATE.withColumn(\n",
    "    \"date_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8685"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_DATE.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------------------+-------+\n",
      "|year|month|day|hour|  weekday|     full_date_time|date_id|\n",
      "+----+-----+---+----+---------+-------------------+-------+\n",
      "|2017|   01|  5|   1| Thursday|2017-01-05 01:00:00|      1|\n",
      "|2017|   01| 11|   8|Wednesday|2017-01-11 08:00:00|      2|\n",
      "|2017|   01| 21|  22| Saturday|2017-01-21 22:00:00|      3|\n",
      "|2017|   02|  7|  11|  Tuesday|2017-02-07 11:00:00|      4|\n",
      "|2017|   02|  9|   7| Thursday|2017-02-09 07:00:00|      5|\n",
      "|2017|   02|  9|  22| Thursday|2017-02-09 22:00:00|      6|\n",
      "|2017|   02| 16|   5| Thursday|2017-02-16 05:00:00|      7|\n",
      "|2017|   02| 23|  18| Thursday|2017-02-23 18:00:00|      8|\n",
      "|2017|   02| 25|  11| Saturday|2017-02-25 11:00:00|      9|\n",
      "|2017|   02| 26|  13|   Sunday|2017-02-26 13:00:00|     10|\n",
      "|2017|   03| 12|  13|   Sunday|2017-03-12 13:00:00|     11|\n",
      "|2017|   04|  1|   8| Saturday|2017-04-01 08:00:00|     12|\n",
      "|2017|   04|  6|  14| Thursday|2017-04-06 14:00:00|     13|\n",
      "|2017|   04| 21|  17|   Friday|2017-04-21 17:00:00|     14|\n",
      "|2017|   05|  6|  15| Saturday|2017-05-06 15:00:00|     15|\n",
      "|2017|   05|  9|  14|  Tuesday|2017-05-09 14:00:00|     16|\n",
      "|2017|   05| 12|  17|   Friday|2017-05-12 17:00:00|     17|\n",
      "|2017|   06| 13|  10|  Tuesday|2017-06-13 10:00:00|     18|\n",
      "|2017|   06| 15|   6| Thursday|2017-06-15 06:00:00|     19|\n",
      "|2017|   06| 20|  22|  Tuesday|2017-06-20 22:00:00|     20|\n",
      "+----+-----+---+----+---------+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_DATE.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating CARD Dim\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Column Name</th>\n",
    "      <th>Data Type</th>\n",
    "       </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>card_type_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>card_type</td>\n",
    "      <td>VARCHAR(20)</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>PRIMARY KEY</td>\n",
    "      <td>card_type_id</td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying CARD TYPE DIM From Source File.\n",
    "temp_dim_card= df.select('card_type')\n",
    "#De-Duplicating Data based on DATE parameters\n",
    "DIM_CARD = temp_dim_card.dropDuplicates((['card_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_CARD = DIM_CARD.withColumn(\n",
    "    \"card_type_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[card_type: string, card_type_id: int]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_CARD.orderBy('card_type_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_CARD.count()   #count 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           card_type|card_type_id|\n",
      "+--------------------+------------+\n",
      "|     Dankort - on-us|           1|\n",
      "|              CIRRUS|           2|\n",
      "|         HÃƒÂ¦vekort|           3|\n",
      "|                VISA|           4|\n",
      "|  Mastercard - on-us|           5|\n",
      "|             Maestro|           6|\n",
      "|Visa Dankort - on-us|           7|\n",
      "|        Visa Dankort|           8|\n",
      "|            VisaPlus|           9|\n",
      "|          MasterCard|          10|\n",
      "|             Dankort|          11|\n",
      "| HÃƒÂ¦vekort - on-us|          12|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DIM_CARD.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Steps for having the Primary keys in the Fact Table**\n",
    "\n",
    "* Used appropriate joins\n",
    "* Rearranged fields when necessary\n",
    "* created few temp columns and later deleted\n",
    "* checked the record counts in each step to make sure there is no data discrepency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left outer join on df and DIM_ATM_TEMP (which has the join for location and ATM)\n",
    "df1 = df.join(DIM_ATM_TEMP,on=['atm_id','atm_manufacturer','atm_location','atm_streetname','atm_street_number', 'atm_zipcode', 'atm_lat', 'atm_lon'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()  ## contains location_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()  # count is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1.location_id.isNotNull()).count()   ## count is as expected 2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming as there is clash on location id where cols from ATM location also gets copied during join. \n",
    "## These renamed cols will be retained and reverted to previous values while joined table cols will be deleted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumnRenamed('location_id','tlocation_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.join(DIM_ATM_PK,on=['atm_id','atm_manufacturer','atm_location','atm_streetname','atm_street_number', 'atm_zipcode', 'atm_lat', 'atm_lon'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- tlocation_id: integer (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()  #contains location_id and atm_prim_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()  ## count is 2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.filter(df2.atm_prim_id.isNotNull()).count()  ## count as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.drop('tlocation_id')   ### drop the column as not required\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "## joining Primary key for card type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.withColumnRenamed('card_type','card_types')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df3.join(DIM_CARD, df3.card_types == DIM_CARD.card_type,how='LEFT')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_types: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index.printSchema()  #contains location_id and atm_prim_id and card_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------------+------------+---------------+\n",
      "|year|  month|      card_type|card_type_id|     card_types|\n",
      "+----+-------+---------------+------------+---------------+\n",
      "|2017|January|Dankort - on-us|           1|Dankort - on-us|\n",
      "|2017|January|Dankort - on-us|           1|Dankort - on-us|\n",
      "|2017|January|Dankort - on-us|           1|Dankort - on-us|\n",
      "|2017|January|Dankort - on-us|           1|Dankort - on-us|\n",
      "|2017|January|Dankort - on-us|           1|Dankort - on-us|\n",
      "+----+-------+---------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index.select('year', 'month', 'card_type', 'card_type_id','card_types').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = df_index.drop('card_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index= df_index.withColumnRenamed('card_types','card_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Checking point to make sure no previous data is disturbed.\n",
    "DIM_LOC.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM_LOC.count()  ## 109 as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### joining PK for date dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index.withColumn(\"month\",from_unixtime(unix_timestamp(col(\"Month\"),'MMM'),'MM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.withColumn('full_date_time',sf.concat(sf.col('year'),sf.lit('/'),sf.col('month'),sf.lit('/'),sf.col('day'),sf.lit(' '),sf.col('hour'),sf.lit(':'),sf.lit('00:00')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.withColumn('full_date_time', unix_timestamp(df_index2['full_date_time'], 'yyyy/MM/dd HH:mm:ss').cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- full_date_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Renaming only for convenience and will be deleted sooner after purpose is sevred\n",
    "df_index2 = df_index2.withColumnRenamed('year','ryear')\n",
    "df_index2 = df_index2.withColumnRenamed('month','rmonth')\n",
    "df_index2 = df_index2.withColumnRenamed('day','rday')\n",
    "df_index2 = df_index2.withColumnRenamed('weekday','rweekday')\n",
    "df_index2 = df_index2.withColumnRenamed('hour','rhour')\n",
    "df_index2 = df_index2.withColumnRenamed('full_date_time','rfull_date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- ryear: integer (nullable = true)\n",
      " |-- rmonth: string (nullable = true)\n",
      " |-- rday: integer (nullable = true)\n",
      " |-- rweekday: string (nullable = true)\n",
      " |-- rhour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- rfull_date_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.join(DIM_DATE, df_index2.rfull_date_time == DIM_DATE.full_date_time,how='LEFT') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- ryear: integer (nullable = true)\n",
      " |-- rmonth: string (nullable = true)\n",
      " |-- rday: integer (nullable = true)\n",
      " |-- rweekday: string (nullable = true)\n",
      " |-- rhour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- rfull_date_time: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- full_date_time: timestamp (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index2.printSchema()  ## contains all the primary key for dimension table i.e location_id,atm_prim_id,card_type_id and date_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index2.count()  ## count as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.drop('year','month','day','weekday','hour','full_date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.withColumnRenamed('ryear','year')\n",
    "df_index2 = df_index2.withColumnRenamed('rmonth','month')\n",
    "df_index2 = df_index2.withColumnRenamed('rday','day')\n",
    "df_index2 = df_index2.withColumnRenamed('rweekday','weekday')\n",
    "df_index2 = df_index2.withColumnRenamed('rhour','hour')\n",
    "df_index2 = df_index2.withColumnRenamed('rfull_date_time','full_date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- full_date_time: timestamp (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.drop('full_date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- atm_id: string (nullable = true)\n",
      " |-- atm_manufacturer: string (nullable = true)\n",
      " |-- atm_location: string (nullable = true)\n",
      " |-- atm_streetname: string (nullable = true)\n",
      " |-- atm_street_number: integer (nullable = true)\n",
      " |-- atm_zipcode: integer (nullable = true)\n",
      " |-- atm_lat: double (nullable = true)\n",
      " |-- atm_lon: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- weather_lat: double (nullable = true)\n",
      " |-- weather_lon: double (nullable = true)\n",
      " |-- weather_city_id: integer (nullable = true)\n",
      " |-- weather_city_name: string (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- pressure: integer (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- wind_speed: integer (nullable = true)\n",
      " |-- wind_deg: integer (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_index2.printSchema()   ## Final schema looks as below with all columns for FACT table creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Fact table\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Column Name</th>\n",
    "      <th>Data Type</th>\n",
    "       </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>trans_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>atm_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "<tr>\n",
    "      <td>weather_loc_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>date_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td>card_type_id</td>\n",
    "      <td>INT</td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Primary key trans_id for fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index2 = df_index2.withColumn(\n",
    "    \"trans_id\",\n",
    "    row_number().over(Window.orderBy(monotonically_increasing_id()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_ATM_TRANS = df_index2.select('trans_id','atm_prim_id','location_id','date_id','card_type_id','atm_status','currency','service','transaction_amount','message_code','message_text',\n",
    "                                     'rain_3h','clouds_all','weather_id','weather_main','weather_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trans_id: integer (nullable = true)\n",
      " |-- atm_prim_id: integer (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- date_id: integer (nullable = true)\n",
      " |-- card_type_id: integer (nullable = true)\n",
      " |-- atm_status: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- transaction_amount: integer (nullable = true)\n",
      " |-- message_code: string (nullable = true)\n",
      " |-- message_text: string (nullable = true)\n",
      " |-- rain_3h: double (nullable = true)\n",
      " |-- clouds_all: integer (nullable = true)\n",
      " |-- weather_id: integer (nullable = true)\n",
      " |-- weather_main: string (nullable = true)\n",
      " |-- weather_description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FACT_ATM_TRANS.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All rows loaded as expected and count is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.count()  #2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+-------+------------+----------+\n",
      "|trans_id|atm_prim_id|location_id|date_id|card_type_id|atm_status|\n",
      "+--------+-----------+-----------+-------+------------+----------+\n",
      "|       1|        150|         98|      1|          10|    Active|\n",
      "|       2|        113|         16|      1|          10|    Active|\n",
      "|       3|         31|         55|      2|           1|    Active|\n",
      "|       4|          8|         66|      2|           1|  Inactive|\n",
      "|       5|         62|          6|      2|           1|    Active|\n",
      "|       6|         36|          9|      2|           1|    Active|\n",
      "|       7|         36|          9|      2|           1|    Active|\n",
      "|       8|        135|         75|      2|           1|    Active|\n",
      "|       9|        127|         32|      2|           3|    Active|\n",
      "|      10|         57|         27|      2|           4|    Active|\n",
      "+--------+-----------+-----------+-------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FACT_ATM_TRANS.select('trans_id','atm_prim_id','location_id','date_id','card_type_id','atm_status').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.atm_prim_id.isNotNull()).count()   #2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.location_id.isNotNull()).count()   #2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.date_id.isNotNull()).count()     #2468572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468572"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACT_ATM_TRANS.filter(FACT_ATM_TRANS.card_type_id.isNotNull()).count()   #2468572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copying FACT & DIMS to S3 bucket \"redshiftpiyushi\" and folder ETL\n",
    "\n",
    "**Steps followed**\n",
    "1. create s3 bucket and folder in dashboard\n",
    "2. Setting spark.hadoop.fs.s3a.access.key and spark.hadoop.fs.s3a.secret.key in spark-defaults.conf\n",
    "3. write the fact and dimension table under s3 bucket/Folder created for this purpose\n",
    "\n",
    "\n",
    "\n",
    "**df.write.save(\"s3a//<redshiftbucket/folder/tablename>\",format='csv',header='true')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\",\"AKIA2O332MRSX5WUWE4Q\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\",\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LOC.write.save(\"s3a://redshiftpiyushi/ETL/DIM_LOC\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_ATM.write.save(\"s3a://redshiftpiyushi/ETL/DIM_ATM\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_DATE.write.save(\"s3a://redshiftpiyushi/ETL/DIM_DATE\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_CARD.write.save(\"s3a://redshiftpiyushi/ETL/DIM_CARD\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_ATM_TRANS.write.save(\"s3a://redshiftpiyushi/ETL/FACT_ATM_TRANS\",format='csv',header='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After this we are going to check the s3 bucket for the files to be created and then create the tables in redshift and load this data in those tables for analytical queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
